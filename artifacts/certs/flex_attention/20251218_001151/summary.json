{
  "args": {
    "artifacts_dir": "artifacts",
    "atol": null,
    "batch_size": 1,
    "compile": true,
    "device": "cuda",
    "dtype": "bfloat16",
    "kv_chunk_len": 7,
    "kv_prefix_len": 13,
    "model": "standard",
    "n_embd": 128,
    "n_head": 4,
    "n_kv_head": 2,
    "n_layer": 2,
    "rtol": null,
    "run_id": null,
    "seed": 0,
    "sequence_len": 64,
    "suite": false,
    "vocab_size": 1024,
    "write_artifacts": true
  },
  "argv": [
    "scripts/verify_flex_correctness.py",
    "--model",
    "standard",
    "--device",
    "cuda",
    "--dtype",
    "bfloat16",
    "--compile",
    "--batch-size",
    "1",
    "--sequence-len",
    "64",
    "--vocab-size",
    "1024",
    "--n-layer",
    "2",
    "--n-head",
    "4",
    "--n-kv-head",
    "2",
    "--n-embd",
    "128"
  ],
  "command": "uv run python scripts/verify_flex_correctness.py --model standard --device cuda --dtype bfloat16 --compile --batch-size 1 --sequence-len 64 --vocab-size 1024 --n-layer 2 --n-head 4 --n-kv-head 2 --n-embd 128",
  "config": {
    "flex": {
      "attention_type": "standard",
      "compile_backend": "inductor",
      "compile_dynamic": null,
      "compile_flex_attention": false,
      "compile_fullgraph": false,
      "compile_mode": null,
      "n_embd": 128,
      "n_head": 4,
      "n_kv_head": 2,
      "n_layer": 2,
      "optimizer_type": "adamw",
      "sequence_len": 64,
      "use_flex_attention": true,
      "vocab_size": 1024
    },
    "ref": {
      "attention_type": "standard",
      "compile_backend": "inductor",
      "compile_dynamic": null,
      "compile_flex_attention": false,
      "compile_fullgraph": false,
      "compile_mode": null,
      "n_embd": 128,
      "n_head": 4,
      "n_kv_head": 2,
      "n_layer": 2,
      "optimizer_type": "adamw",
      "sequence_len": 64,
      "use_flex_attention": false,
      "vocab_size": 1024
    }
  },
  "device": "cuda",
  "dtype": "bfloat16",
  "git": {
    "branch": "main",
    "commit": "95ab717",
    "commit_full": "95ab717124a53d816acfdc82d21628e443b811df",
    "dirty": true,
    "message": "Comprehensively revise README.md to reflect dual-implementation architecture"
  },
  "gpu": {
    "available": true,
    "count": 2,
    "cuda_version": "12.8",
    "memory_gb": [
      23.5164794921875,
      23.5135498046875
    ],
    "names": [
      "NVIDIA GeForce RTX 4090",
      "NVIDIA GeForce RTX 4090"
    ]
  },
  "python": {
    "executable": "/data/projects/model_guided_research/.venv/bin/python3",
    "version": "3.13.0 (main, Oct 16 2024, 03:23:02) [Clang 18.1.8 ]"
  },
  "results": {
    "checks": [
      {
        "max_abs": 0.015625,
        "max_rel": 17.042552947998047,
        "mean_abs": 0.00013779025175608695,
        "name": "single/full_forward",
        "note": "",
        "passed": true
      },
      {
        "max_abs": 0.0,
        "max_rel": 0.0,
        "mean_abs": 0.0,
        "name": "single/kv_decode_last",
        "note": "",
        "passed": true
      },
      {
        "max_abs": 0.0078125,
        "max_rel": 89.03375244140625,
        "mean_abs": 0.0011847353307530284,
        "name": "single/kv_chunk_decode",
        "note": "",
        "passed": true
      }
    ],
    "ok": true
  },
  "system": {
    "cpu_count": 32,
    "cpu_count_logical": 64,
    "hostname": "threadripperje",
    "memory_gb": 499.2872734069824,
    "nanochat_base_dir": "/home/ubuntu/.cache/nanochat",
    "nanochat_base_dir_env": null,
    "platform": "Linux",
    "python_version": "3.13.0",
    "torch_version": "2.9.1+cu128",
    "user": "ubuntu",
    "working_dir": "/data/projects/model_guided_research"
  }
}
