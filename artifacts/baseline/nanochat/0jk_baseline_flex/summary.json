{
  "argv": [
    "/data/projects/model_guided_research/nanochat/train.py",
    "--device",
    "cuda",
    "--auto-download-data",
    "--target-flops",
    "2e12",
    "--log-interval",
    "10",
    "--warmup-steps",
    "5",
    "--use-flex-attention",
    "--run-id",
    "0jk_baseline_flex"
  ],
  "budget": {
    "flops_per_step_est": 92006252544,
    "flops_per_token_est": 44924928,
    "max_steps": 22,
    "planned_total_flops_est": 2024137555968,
    "target_flops": 2000000000000.0,
    "tokens_per_step_global": 2048,
    "warmup_steps": 5
  },
  "command": "uv run python -m nanochat.train --device cuda --auto-download-data --target-flops 2e12 --log-interval 10 --warmup-steps 5 --use-flex-attention --run-id 0jk_baseline_flex",
  "command_argv": "/data/projects/model_guided_research/nanochat/train.py --device cuda --auto-download-data --target-flops 2e12 --log-interval 10 --warmup-steps 5 --use-flex-attention --run-id 0jk_baseline_flex",
  "command_module": "python -m nanochat.train --device cuda --auto-download-data --target-flops 2e12 --log-interval 10 --warmup-steps 5 --use-flex-attention --run-id 0jk_baseline_flex",
  "config": {
    "attention_type": "standard",
    "n_embd": 128,
    "n_head": 4,
    "n_kv_head": 4,
    "n_layer": 4,
    "optimizer_type": "adamw",
    "sequence_len": 256,
    "use_flex_attention": true,
    "vocab_size": 50304
  },
  "dataset": {
    "parquet_files": [
      "/home/ubuntu/.cache/nanochat/base_data/shard_00000.parquet",
      "/home/ubuntu/.cache/nanochat/base_data/shard_00001.parquet"
    ],
    "parquet_files_count": 2
  },
  "ddp": {
    "enabled": false,
    "local_rank": 0,
    "rank": 0,
    "world_size": 1
  },
  "env": {
    "TORCHINDUCTOR_CACHE_DIR": "/tmp/torchinductor_ubuntu"
  },
  "git": {
    "branch": "main",
    "commit": "95ab717",
    "commit_full": "95ab717124a53d816acfdc82d21628e443b811df",
    "dirty": true,
    "message": "Comprehensively revise README.md to reflect dual-implementation architecture"
  },
  "gpu": {
    "available": true,
    "count": 2,
    "cuda_version": "12.8",
    "memory_gb": [
      23.5164794921875,
      23.5135498046875
    ],
    "names": [
      "NVIDIA GeForce RTX 4090",
      "NVIDIA GeForce RTX 4090"
    ]
  },
  "python": {
    "executable": "/data/projects/model_guided_research/.venv/bin/python3",
    "version": "3.13.0 (main, Oct 16 2024, 03:23:02) [Clang 18.1.8 ]"
  },
  "results": {
    "losses": [
      10.825838088989258,
      10.806350708007812,
      10.789953231811523,
      10.773990631103516,
      10.769632339477539,
      10.756925582885742,
      10.743977546691895,
      10.691095352172852,
      10.716022491455078,
      10.710006713867188,
      10.68144416809082,
      10.633811950683594,
      10.684429168701172,
      10.654640197753906,
      10.59218978881836,
      10.535146713256836,
      10.542198181152344,
      10.532289505004883,
      10.503652572631836,
      10.49365234375,
      10.429519653320312,
      10.382643699645996
    ],
    "measured_steps": 17,
    "measured_time_s": 1.6769905470428057,
    "measured_tokens": 34816,
    "peak_memory_allocated_gb": 1.542665958404541,
    "step_times_s": [
      1.147244966996368,
      0.10955988097703084,
      0.11176292900927365,
      0.10816847201203927,
      0.10692809702595696,
      0.1006441960344091,
      0.12085604801541194,
      0.1150062849628739,
      0.12364816502667964,
      0.11857418197905645,
      0.11444610002217814,
      0.11061381601030007,
      0.11263751599472016,
      0.07983066199813038,
      0.08349042199552059,
      0.07856007997179404,
      0.0877758510177955,
      0.08400103397434577,
      0.08303012500982732,
      0.08358326699817553,
      0.08307587099261582,
      0.08083193702623248
    ],
    "tflops_per_second_est": 0.9326864101924337,
    "tokens_per_second": 20760.99955446637
  },
  "run_id": "0jk_baseline_flex",
  "system": {
    "cpu_count": 32,
    "cpu_count_logical": 64,
    "hostname": "threadripperje",
    "memory_gb": 499.2872734069824,
    "nanochat_base_dir": "/home/ubuntu/.cache/nanochat",
    "nanochat_base_dir_env": null,
    "platform": "Linux",
    "python_version": "3.13.0",
    "torch_version": "2.9.1+cu128",
    "user": "ubuntu",
    "working_dir": "/data/projects/model_guided_research"
  }
}
